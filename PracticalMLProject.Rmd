---
title: "Practical Machine Learning Project"
author: "Ann"
date: "November 17, 2015"
output: html_document
---
```{r echo=FALSE, message=FALSE, warning=FALSE}
library(caret)
library(manipulate)
library(ggplot2)
library(stringr)
library(kernlab)
library(dplyr)
source("clean.R")
source("clean2.R")
source("CreateSubmissionFiles.R")
```

####Synopsis
This project uses the Weight Lifting Exercises (WLE) Dataset from the Human Activity Recognition project (http://groupware.les.inf.puc-rio.br/har#weight_lifting_exercises). This data is gathered from 4 sensors attached to the test subject and the dumbbell. Measurements were taking from the devices while the subject performed multiple sets of Unilateral dumbbell bicep curls (unilateral meaning the reps were performed on only one arm at a time). The subject was told to perform the reps in 5 different manners: performing the activity correctly (A) and incorrectly in 4 different manners (B, C, D, and E). Data was then gathered from multiple test subjects using this same procedure. 

The purpose of this project is to use this WLE dataset to create a prediction algorithm that can be use for to later make predications on new raw data and predict an outcome. The implications for this algorithms use is that it could supply people with real-time feedback while exercising to alerting them if they are doing the exercise incorrectly.  

1. Load and Prepare Data
Perform cleaning and preprocessing to the Training set data.
```{r, warning=FALSE}
pmlRawTraining <- read.csv("pml-training.csv", header = TRUE, stringsAsFactors = FALSE)
pmlTraining <- subset(pmlRawTraining[,c(grep("user_name", names(pmlRawTraining)),
                                        grep("classe", names(pmlRawTraining)))])
pmlTraining$user_name <- as.factor(pmlTraining$user_name)
pmlTraining$classe <- as.factor(pmlTraining$classe)

pmlRawTraining <- clean(pmlRawTraining)

preObj <- preProcess(pmlRawTraining[,-2], method=c("center","scale"))
pmlRawTraining <- predict(preObj, pmlRawTraining)
pmlTraining <- cbind(pmlTraining, pmlRawTraining)
dim(pmlTraining); 
```
Perform the same cleaning and preprocessing process to the final Test set data.
```{r}
pmlRawTest <- read.csv("pml-testing.csv", header = TRUE, stringsAsFactors = FALSE)
pmlTest <- subset(pmlRawTest[,c(grep("user_name", names(pmlRawTest)),grep("problem_id", names(pmlRawTest)))])
pmlTest$user_name <- as.factor(pmlTest$user_name)
pmlRawTest <- clean(pmlRawTest)

pmlRawTest <- predict(preObj, pmlRawTest)
pmlTest <- cbind(pmlTest, pmlRawTest)
dim(pmlTest)
```

Perform data slicing to partition data into 3 groups:   

* Training Set : Data used to identify features and develop a predictive model   
* Cross Validtion (CV) Set : Unbiased data (data that was not used for model building) for testing the predictive model   
* Final Test Set : Data that is applied only one-time to the final predictive model for predictions, i.e. this data is not used for performing any analysis or model building)

The final Test set has already been partitioned within pml_Test.csv leaving only the pmlTraining data needing to be partitioned into Training and CV sets. The pmlTraining data is then partitioned 75% / 25% into Training and CV sets respectively.
```{r}
inTrain <- createDataPartition(y=pmlTraining$classe, p=0.75, list=FALSE)
pmlCV <- pmlTraining [-inTrain,]
dim(pmlCV)
pmlTraining <- pmlTraining[inTrain,]
dim(pmlTraining)
```

2. Perform Analysis and Model Building

The caret package is used for prediction analysis. The seed is set so that the project results repeated independently by others. The caret training control is set to perform cross-validation using random sampling 10 times on the training data to build the model. Looking at the data it was clear this was a multi-classification problem, predict an outcome classifcation from the set   of A, B, C, D or E. This then excluded using linear (indicated by the multiple outcomes A, B, and C, etc not being linear) or binomial (indicated by having more then to possible outcome classifications) models.
```{r, message=FALSE, warning=FALSE, cache=TRUE}
set.seed(2889)
fitControl <- trainControl(method = "cv",
                           number = 10,
                           repeats = 1)

#Time using a quarter of the training data
# inTrainQuarter <- createDataPartition(y=pmlTraining$classe, p=0.05, list=FALSE)
# trainingQuarter <- pmlTraining[inTrainQuarter,]
# pmlTraining <- trainingQuarter                

modelFit <- train(classe ~., data = pmlTraining, method="rf", trControl=fitControl)
modelFit
modelFit$finalModel
predictionsPmlTraining <- predict(modelFit, pmlTraining)
confusionMatrix(predictionsPmlTraining, pmlTraining$classe)
```
The in-sample error rate is the accuracy found when making predictions on data that was used in creating the model. This accuracy rate will be higher (more optimistic) as the model has been created and fitted using this data.  

4. Validate/Refine On Cross Validtion Test Set

Cross validation is done by splitting the training set into training/CV sets. Next the model is built using the training set then tested/verified on the CV data set. This process is repeated and the error estimates are averaged to determine the final model accuracy. This the cross validation process is used to:   

* Pick variables to include in the model   
* Pick the type of prediction function to use   
* Pick the parameters in the prediction function   
* Compare different predictors   
```{r, message=FALSE, warning=FALSE}
predictionsPmlCV <- predict(modelFit, pmlCV)
confusionMatrix(predictionsPmlCV, pmlCV$classe)
```
The out-of-sample error rate is the accuracy found when making predictions on data that was not used in creating the model. This accuracy rate will generally be lower (less optimistic) that used on the data that was used to originally create the model. This is true shown by the CV set accuracy is lower than the Traning set accuracy.  

5. Apply Prediction Model One Time to Final Test Set

```{r, message=FALSE, warning=FALSE}
predictionsPmlTest <- predict(modelFit, pmlTest)
#predictionsPmlTest
pml_write_files(predictionsPmlTest)
```
####Results
The results of project where a prediction model was built using cross-validation with the caret modeling package within R Studio. The model was then used to against the pmlTest data. The prediction results against the pmlTest data using the model were 20 out-of 20 correct answers. 

```{r, echo=FALSE, cache=FALSE}
save.image(file="markdown_results.rdata")
```